{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the range of dates here\n",
    "seven_days = pd.date_range(start = '2017-1-1', periods = 7)\n",
    "\n",
    "# Iterate over the dates and print the number and name of the weekday\n",
    "for day in seven_days:\n",
    "    print(day.dayofweek, day.weekday_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and resamplig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('nyc.csv')\n",
    "\n",
    "# Inspect data\n",
    "print(data.info())\n",
    "\n",
    "# Convert the date column to datetime64\n",
    "data['date'] = pd.to_datetime(data.date)\n",
    "\n",
    "# Set date column as index\n",
    "data.set_index('date', inplace = True)\n",
    "\n",
    "# Inspect data \n",
    "print(data.info())\n",
    "\n",
    "# Plot data\n",
    "data.plot(subplots=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare annual stock price trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe prices here\n",
    "prices = pd.DataFrame()\n",
    "\n",
    "# Select data for each year and concatenate with prices here \n",
    "for year in ['2013', '2014', '2015']:\n",
    "    price_per_year = yahoo.loc[year, ['price']].reset_index(drop=True)\n",
    "    price_per_year.rename(columns={'price': year}, inplace=True)\n",
    "    prices = pd.concat([prices, price_per_year], axis=1)\n",
    "\n",
    "# Plot prices\n",
    "prices.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set and change time series frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect data\n",
    "print(co.info())\n",
    "\n",
    "# Set the frequency to calendar daily\n",
    "co = co.asfreq('D')\n",
    "\n",
    "# Plot the data\n",
    "co.plot(subplots= True)\n",
    "plt.show()\n",
    "\n",
    "# Set frequency to monthly\n",
    "co = co.asfreq('M')\n",
    "\n",
    "# Plot the data\n",
    "co.plot(subplots= True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shifting time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data here\n",
    "google = pd.read_csv('google.csv', parse_dates = ['Date'], index_col = 'Date')\n",
    "\n",
    "# Set data frequency to business daily\n",
    "google = google.asfreq('B')\n",
    "\n",
    "# Create 'lagged' and 'shifted'\n",
    "google['lagged'] = google.Close.shift(-90)\n",
    "google['shifted'] = google.Close.shift(90)\n",
    "\n",
    "# Plot the google price series\n",
    "google.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created shifted_30 here\n",
    "yahoo['shifted_30'] = yahoo.price.shift(30)\n",
    "\n",
    "# Subtract shifted_30 from price\n",
    "yahoo['change_30'] = yahoo.price.sub(yahoo.shifted_30)\n",
    "\n",
    "# Get the 30-day price difference\n",
    "yahoo['diff_30'] = yahoo.price.diff(30)\n",
    "\n",
    "# Inspect the last five rows of price\n",
    "print(yahoo.tail())\n",
    "\n",
    "# Show the value_counts of the difference between change_30 and diff_30\n",
    "print(yahoo.change_30.sub(yahoo.diff_30).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create daily_return\n",
    "google['daily_return'] = google.Close.pct_change(1)*100\n",
    "\n",
    "# Create monthly_return\n",
    "google['monthly_return'] = google.Close.pct_change(30)*100\n",
    "\n",
    "# Create annual_return\n",
    "google['annual_return'] = google.Close.pct_change(360)*100\n",
    "\n",
    "# Plot the result\n",
    "google.plot(subplots=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Time Series Growth Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a 100 base stocks comparisson graphic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data here\n",
    "prices = pd.read_csv('asset_classes.csv', parse_dates = ['DATE'], index_col = 'DATE')\n",
    "\n",
    "# Inspect prices here\n",
    "print(prices.info())\n",
    "\n",
    "# Select first prices\n",
    "first_prices = prices.iloc[0]\n",
    "\n",
    "# Create normalized\n",
    "normalized = prices.div(first_prices).mul(100)\n",
    "\n",
    "# Plot normalized\n",
    "normalized.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with a bechmark or subtract the benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using reindex() and asfreq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set start and end dates\n",
    "start = '2016-1-1'\n",
    "end = '2016-2-29'\n",
    "\n",
    "# Create monthly_dates here\n",
    "monthly_dates = pd.date_range(start = start, end = end, freq = 'M')\n",
    "\n",
    "# Create and print monthly here\n",
    "monthly = pd.Series(data = [1,2], index = monthly_dates)\n",
    "print(monthly)\n",
    "\n",
    "# Create weekly_dates here\n",
    "weekly_dates = pd.date_range(start = start, end = end, freq = 'W')\n",
    "\n",
    "\n",
    "# Print monthly, reindexed using weekly_dates\n",
    "print(monthly.reindex(index = weekly_dates, method = None))\n",
    "print(monthly.reindex(index = weekly_dates, method = 'bfill'))\n",
    "print(monthly.reindex(index = weekly_dates, method = 'ffill'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data here\n",
    "data = pd.read_csv('unemployment.csv', parse_dates=['date'], index_col='date')\n",
    "\n",
    "# Show first five rows of weekly series\n",
    "print(data.asfreq('W').head())\n",
    "\n",
    "# Show first five rows of weekly series with bfill option\n",
    "print(data.asfreq('W', method='bfill').head())\n",
    "\n",
    "# Create weekly series with ffill option and show first five rows\n",
    "weekly_ffill = data.asfreq('W', method='ffill')\n",
    "print(weekly_ffill.head())\n",
    "\n",
    "# Plot weekly_fill starting 2015 here \n",
    "weekly_ffill.loc['2015':].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling & interpolation with .resample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect data here\n",
    "print(monthly.info())\n",
    "\n",
    "# Create weekly dates\n",
    "weekly_dates = pd.date_range(start = monthly.index.min(), end = monthly.index.max(), freq = 'W')\n",
    "\n",
    "# Reindex monthly to weekly data\n",
    "weekly = monthly.reindex(weekly_dates)\n",
    "\n",
    "# Create ffill and interpolated columns\n",
    "weekly['ffill'] = weekly.UNRATE.ffill()\n",
    "weekly['interpolated'] = weekly.UNRATE.interpolate()\n",
    "\n",
    "# Plot weekly\n",
    "weekly.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import & inspect data here\n",
    "data = pd.read_csv('debt_unemployment.csv', parse_dates = ['date'], index_col = 'date')\n",
    "print(data.info())\n",
    "\n",
    "# Interpolate and inspect here\n",
    "interpolated = data.interpolate()\n",
    "print(interpolated.info())\n",
    "\n",
    "# Plot interpolated data here\n",
    "interpolated.plot(secondary_y = 'Unemployment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downsampling & aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and inspect data here\n",
    "ozone = pd.read_csv('ozone.csv', parse_dates = ['date'], index_col = 'date')\n",
    "print(ozone.info())\n",
    "\n",
    "# Calculate and plot the weekly average ozone trend\n",
    "ozone.resample('W').mean().plot()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and plot the monthly average ozone trend\n",
    "ozone.resample('M').mean().plot()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and plot the annual average ozone trend\n",
    "ozone.resample('A').mean().plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and inspect data here\n",
    "stocks = pd.read_csv('stocks.csv', parse_dates = ['date'], index_col = 'date')\n",
    "print(stocks.info())\n",
    "\n",
    "# Calculate and plot the monthly averages\n",
    "monthly_average = stocks.resample('M').mean()\n",
    "monthly_average.plot(subplots=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and inspect gdp_growth here\n",
    "gdp_growth = pd.read_csv('gdp_growth.csv', parse_dates = ['date'], index_col = 'date')\n",
    "print(gdp_growth.info())\n",
    "\n",
    "# Import and inspect djia here\n",
    "djia = pd.read_csv('djia.csv', parse_dates = ['date'], index_col = 'date')\n",
    "print(djia.info())\n",
    "\n",
    "# Calculate djia quarterly returns here \n",
    "djia_quarterly = djia.resample('QS').first()\n",
    "djia_quarterly_return = djia_quarterly.pct_change().mul(100)\n",
    "\n",
    "# Concatenate, rename and plot djia_quarterly_return and gdp_growth here \n",
    "data = pd.concat([gdp_growth, djia_quarterly_return], axis = 1)\n",
    "data.columns = ['gdp', 'djia']\n",
    "data.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data here\n",
    "sp500 = pd.read_csv('sp500.csv', parse_dates=['date'], index_col = 'date')\n",
    "print(sp500.info())\n",
    "\n",
    "# Calculate daily returns here\n",
    "daily_returns = sp500.squeeze().pct_change()\n",
    "\n",
    "# Resample and calculate statistics\n",
    "stats = daily_returns.resample('M').agg(['mean', 'median', 'std'])\n",
    "\n",
    "# Plot stats here\n",
    "stats.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rolling window functions with pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and inspect ozone data here\n",
    "data = pd.read_csv('ozone.csv', parse_dates = ['date'], index_col = 'date')\n",
    "print(data.info())\n",
    "\n",
    "# Calculate 90d and 360d rolling mean for the last price\n",
    "data['90D'] = data.Ozone.rolling('90D').mean()\n",
    "data['360D'] = data.Ozone.rolling('360D').mean()\n",
    "\n",
    "# Plot data\n",
    "data['2010':].plot(title = 'New York City')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and inspect ozone data here\n",
    "data = pd.read_csv('ozone.csv', parse_dates=['date'], index_col='date').dropna()\n",
    "\n",
    "# Calculate the rolling mean and std here\n",
    "rolling_stats = data.Ozone.rolling(360).agg(['mean', 'std'])\n",
    "\n",
    "# Join rolling_stats with ozone data\n",
    "stats = data.join(rolling_stats)\n",
    "\n",
    "# Plot stats\n",
    "stats.plot(subplots=True);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample, interpolate and inspect ozone data here\n",
    "data = data.resample('D').interpolate()\n",
    "print(data.info())\n",
    "\n",
    "# Create the rolling window\n",
    "rolling = data.Ozone.rolling(360)\n",
    "\n",
    "# Insert the rolling quantiles to the monthly returns\n",
    "data['q10'] = rolling.quantile(0.1)\n",
    "data['q50'] = rolling.quantile(0.5)\n",
    "data['q90'] = rolling.quantile(0.9)\n",
    "\n",
    "# Plot the data\n",
    "\n",
    "data.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expanding window functions with pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative sum vs .diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate differences\n",
    "differences = data.diff().dropna()\n",
    "\n",
    "# Select start price\n",
    "start_price = data.first('D')\n",
    "\n",
    "# Calculate cumulative sum\n",
    "cumulative_sum = start_price.append(differences).cumsum()\n",
    "\n",
    "# Validate cumulative sum equals data\n",
    "print(data.equals(cumulative_sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cumulative return on $1,000 invested in google vs apple I\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your investment\n",
    "investment = 1000\n",
    "\n",
    "# Calculate the daily returns here\n",
    "returns = data.pct_change()\n",
    "\n",
    "# Calculate the cumulative returns here\n",
    "returns_plus_one = returns + 1\n",
    "cumulative_return = returns_plus_one.cumprod()\n",
    "\n",
    "# Calculate and plot the investment return here \n",
    "cumulative_return.mul(investment).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Define a multi_period_return function\n",
    "def multi_period_return(period_returns):\n",
    "    return (np.prod(period_returns + 1) - 1)\n",
    "    \n",
    "# Calculate daily returns\n",
    "daily_returns = data.pct_change()\n",
    "\n",
    "# Calculate rolling_annual_returns\n",
    "rolling_annual_returns = daily_returns.rolling('360D').apply(multi_period_return)\n",
    "\n",
    "# Plot rolling_annual_returns\n",
    "rolling_annual_returns.mul(100).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study: S&P500 price simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Walk Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import normal, seed, choice\n",
    "\n",
    "# Set seed here\n",
    "seed(42)\n",
    "\n",
    "# Create random_walk\n",
    "random_walk = normal(loc = .001, scale = .01, size =  2500)\n",
    "\n",
    "# Convert random_walk to pd.series\n",
    "random_walk = pd.Series(random_walk)\n",
    "\n",
    "# Create random_prices\n",
    "random_prices = (random_walk + 1).cumprod()\n",
    "\n",
    "# Plot random_prices here\n",
    "random_prices.mul(1000).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate daily_returns here\n",
    "daily_returns = fb.pct_change().dropna()\n",
    "\n",
    "# Get n_obs\n",
    "n_obs = daily_returns.count()\n",
    "\n",
    "# Create random_walk\n",
    "random_walk = choice(daily_returns, n_obs)\n",
    "\n",
    "# Convert random_walk to pd.series\n",
    "random_walk = pd.Series(random_walk)\n",
    "\n",
    "# Plot random_walk distribution\n",
    "sns.distplot(random_walk)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select fb start price here\n",
    "start = fb.price.first('D')\n",
    "\n",
    "# Add 1 to random walk and append to start\n",
    "random_walk = random_walk + 1\n",
    "random_price = start.append(random_walk)\n",
    "\n",
    "# Calculate cumulative product here\n",
    "random_price = random_price.cumprod()\n",
    "\n",
    "# Insert into fb and plot\n",
    "fb['random'] = random_price\n",
    "fb.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Annual return correlations among several stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate year-end prices here\n",
    "annual_prices = data.resample('A').last()\n",
    "\n",
    "# Calculate annual returns here\n",
    "annual_returns = annual_prices.pct_change()\n",
    "\n",
    "# Calculate and print the correlation matrix here\n",
    "correlations = annual_returns.corr()\n",
    "print(correlations)\n",
    "\n",
    "# Visualize the correlations as heatmap here\n",
    "sns.heatmap(correlations, annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select index components and import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore and clean company listing information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect listings\n",
    "print(listings.info())\n",
    "\n",
    "# Move 'stock symbol' into the index\n",
    "listings.set_index('Stock Symbol', inplace = True)\n",
    "\n",
    "# Drop rows with missing 'sector' data\n",
    "listings.dropna(inplace = True)\n",
    "\n",
    "# Select companies with IPO Year before 2019\n",
    "listings = listings[listings['IPO Year']<2019]\n",
    "\n",
    "# Inspect the new listings data\n",
    "print(listings.info())\n",
    "\n",
    "# Show the number of companies per sector\n",
    "print(listings.groupby('Sector').size().sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select and inspect index components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select largest company for each sector\n",
    "components = listings.groupby(['Sector'])['Market Capitalization'].nlargest(1)\n",
    "\n",
    "# Print components, sorted by market cap\n",
    "print(components.sort_values(ascending=False))\n",
    "\n",
    "# Select stock symbols and print the result\n",
    "tickers = components.index.get_level_values('Stock Symbol')\n",
    "print(tickers)\n",
    "\n",
    "# Print company name, market cap, and last price for each component \n",
    "info_cols = ['Company Name', 'Market Capitalization', 'Last Sale']\n",
    "print(listings.loc[tickers, info_cols].sort_values('Market Capitalization', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import index component price information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print tickers\n",
    "print(tickers)\n",
    "\n",
    "# Import prices and inspect result\n",
    "stock_prices = pd.read_csv('stock_prices.csv', parse_dates=['Date'], index_col='Date')\n",
    "print(stock_prices.info())\n",
    "\n",
    "# Calculate the returns\n",
    "price_return = stock_prices.iloc[-1].div(stock_prices.iloc[0]).sub(1).mul(100)\n",
    "\n",
    "# Plot horizontal bar chart of sorted price_return   \n",
    "price_return.sort_values().plot(kind='barh', title='Stock Price Returns')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a market-cap weighted index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
