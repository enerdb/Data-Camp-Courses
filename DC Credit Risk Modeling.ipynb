{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring and Preparing Loan Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding credit risk\n",
    "\n",
    "Expected loss = PD * EAD * LGD\n",
    "* PD - Probability of Default\n",
    "* EAD - Exposure at Default\n",
    "* LGD - Loss Given Default (ratio lost when we sell a debt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the credit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the structure of the data\n",
    "print(cr_loan.dtypes)\n",
    "\n",
    "# Check the first five rows of the data\n",
    "print(cr_loan.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the distribution of loan amounts with a histogram\n",
    "n, bins, patches = plt.hist(x=cr_loan['loan_amnt'], bins='auto', color='blue',alpha=0.7, rwidth=0.85)\n",
    "plt.xlabel(\"Loan Amount\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are 32 000 rows of data so the scatter plot may take a little while to plot.\")\n",
    "\n",
    "# Plot a scatter plot of income against age\n",
    "plt.scatter(cr_loan['person_income'], cr_loan['person_age'],c='blue', alpha=0.5)\n",
    "plt.xlabel('Personal Income')\n",
    "plt.ylabel('Persone Age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crosstab and pivot tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cross table of the loan intent and loan status\n",
    "print(pd.crosstab(cr_loan['loan_intent'], cr_loan['loan_status'], margins = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cross table of home ownership, loan status, and grade\n",
    "print(pd.crosstab(cr_loan['person_home_ownership'],[cr_loan['loan_status'],cr_loan['loan_grade']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cross table of home ownership, loan status, and average percent income\n",
    "print(pd.crosstab(cr_loan['person_home_ownership'], cr_loan['loan_status'],\n",
    "              values=cr_loan['loan_percent_income'], aggfunc='mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a box plot of percentage income by loan status\n",
    "cr_loan.boxplot(column = ['loan_percent_income'], by = 'loan_status')\n",
    "plt.title('Average Percent Income by Loan Status')\n",
    "plt.suptitle('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers in credit data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding outliers with cross tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the cross table for loan status, home ownership, and the max employment length\n",
    "print(pd.crosstab(cr_loan['loan_status'],cr_loan['person_home_ownership'],\n",
    "                  values=cr_loan['person_emp_length'], aggfunc='max'))\n",
    "\n",
    "# Create an array of indices where employment length is greater than 60\n",
    "indices = cr_loan[cr_loan['person_emp_length'] > 60].index\n",
    "\n",
    "# Drop the records from the data based on the indices and create a new dataframe\n",
    "cr_loan_new = cr_loan.drop(indices)\n",
    "\n",
    "# Create the cross table from earlier and include minimum employment length\n",
    "print(pd.crosstab(cr_loan_new['loan_status'],cr_loan_new['person_home_ownership'],\n",
    "            values=cr_loan_new['person_emp_length'], aggfunc=['min','max']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing credit outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scatter plot for age and amount\n",
    "plt.scatter(cr_loan['person_age'], cr_loan['loan_amnt'], c='blue', alpha=0.5)\n",
    "plt.xlabel(\"Person Age\")\n",
    "plt.ylabel(\"Loan Amount\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pandas to drop the record from the data frame and create a new one\n",
    "cr_loan_new = cr_loan.drop(cr_loan[cr_loan['person_age'] > 90].index)\n",
    "\n",
    "# Create a scatter plot of age and interest rate\n",
    "colors = [\"blue\",\"red\"]\n",
    "plt.scatter(cr_loan_new['person_age'], cr_loan_new['loan_int_rate'],\n",
    "            c = cr_loan_new['loan_status'],\n",
    "            cmap = matplotlib.colors.ListedColormap(colors),\n",
    "            alpha=0.5)\n",
    "plt.xlabel(\"Person Age\")\n",
    "plt.ylabel(\"Loan Interest Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk with missing data in loan data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing missing credit data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a null value column array\n",
    "print(cr_loan.columns[cr_loan.isnull().any()])\n",
    "\n",
    "# Print the top five rows with nulls for employment length\n",
    "print(cr_loan[cr_loan['person_emp_length'].isnull()].head())\n",
    "\n",
    "# Impute the null values with the median value for all employment lengths\n",
    "cr_loan['person_emp_length'].fillna((cr_loan['person_emp_length'].median()), inplace=True)\n",
    "\n",
    "# Create a histogram of employment length\n",
    "n, bins, patches = plt.hist(cr_loan['person_emp_length'], bins='auto', color='blue')\n",
    "plt.xlabel(\"Person Employment Length\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the number of nulls\n",
    "print(cr_loan['loan_int_rate'].isna().sum())\n",
    "\n",
    "# Store the array on indices\n",
    "indices = cr_loan[cr_loan['loan_int_rate'].isna()].index\n",
    "\n",
    "# Save the new data without missing data\n",
    "cr_loan_clean = cr_loan.drop(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression for Defaults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression for probability of default\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the X and y data sets\n",
    "X = cr_loan_clean[['loan_int_rate','person_emp_length','person_income']]\n",
    "y = cr_loan_clean[['loan_status']]\n",
    "\n",
    "# Use test_train_split to create the training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=123)\n",
    "\n",
    "# Create and fit the logistic regression model\n",
    "clf_logistic = LogisticRegression(solver='lbfgs').fit(X_train, np.ravel(y_train))\n",
    "\n",
    "# Print the models coefficients\n",
    "print(clf_logistic.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the probability of default\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing coefficients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first five rows of each training set\n",
    "print(X1_train.head())\n",
    "print(X2_train.head())\n",
    "\n",
    "# Create and train a model on the first training data\n",
    "clf_logistic1 = LogisticRegression(solver='lbfgs').fit(X1_train, np.ravel(y_train))\n",
    "\n",
    "# Create and train a model on the second training data\n",
    "clf_logistic2 = LogisticRegression(solver='lbfgs').fit(X2_train, np.ravel(y_train))\n",
    "\n",
    "# Print the coefficients of each model\n",
    "print(clf_logistic1.coef_)\n",
    "print(clf_logistic2.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two data sets for numeric and non-numeric data\n",
    "cred_num = cr_loan_clean.select_dtypes(exclude=['object'])\n",
    "cred_str = cr_loan_clean.select_dtypes(include=['object'])\n",
    "\n",
    "# One-hot encode the non-numeric columns\n",
    "cred_str_onehot = pd.get_dummies(cred_str)\n",
    "\n",
    "# Union the one-hot encoded columns to the numeric ones\n",
    "cr_loan_prep = pd.concat([cred_num, cred_str_onehot], axis=1)\n",
    "\n",
    "# Print the columns in the new data set\n",
    "print(cr_loan_prep.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting probability of default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the logistic regression model on the training data\n",
    "clf_logistic = LogisticRegression(solver='lbfgs').fit(X_train, np.ravel(y_train))\n",
    "\n",
    "# Create predictions of probability for loan status using test data\n",
    "preds = clf_logistic.predict_proba(X_test)\n",
    "\n",
    "# Create dataframes of first five predictions, and first five true labels\n",
    "preds_df = pd.DataFrame(preds[:,1][0:5], columns = ['prob_default'])\n",
    "true_df = y_test.head()\n",
    "\n",
    "# Concatenate and print the two data frames for comparison\n",
    "print(pd.concat([true_df.reset_index(drop = True), preds_df], axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit model performance\n",
    "\n",
    "Accuracy (.score(X_test, y_test)) = Number of correct predictions / Number of predictions\n",
    "\n",
    "Sensitivity = True positive rate\n",
    "\n",
    "Fall-out = false positive rate\n",
    "\n",
    "Precision\n",
    "\n",
    "Recall\n",
    "\n",
    "F1-score\n",
    "\n",
    "Support\n",
    "\n",
    "Threshold = limit probability where we predict 0 or 1.\n",
    "\n",
    "roc_auc_score : Area under curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default classification reporting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe for the probabilities of default\n",
    "preds_df = pd.DataFrame(preds[:,1], columns = ['prob_default'])\n",
    "\n",
    "# Reassign loan status based on the threshold\n",
    "preds_df['loan_status'] = preds_df['prob_default'].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "\n",
    "# Print the row counts for each loan status\n",
    "print(preds_df['loan_status'].value_counts())\n",
    "\n",
    "# Print the classification report\n",
    "target_names = ['Non-Default', 'Default']\n",
    "print(classification_report(y_test, preds_df['loan_status'], target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Report metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification report\n",
    "target_names = ['Non-Default', 'Default']\n",
    "print(classification_report(y_test, preds_df['loan_status'], target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all the non-average values from the report\n",
    "print(precision_recall_fscore_support(y_test,preds_df['loan_status']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visually scoring credit models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictions and store them in a variable\n",
    "preds = clf_logistic.predict_proba(X_test)\n",
    "\n",
    "# Print the accuracy score the model\n",
    "print(clf_logistic.score(X_test, y_test))\n",
    "\n",
    "# Plot the ROC curve of the probabilities of default\n",
    "prob_default = preds[:, 1]\n",
    "fallout, sensitivity, thresholds = roc_curve(y_test, prob_default)\n",
    "plt.plot(fallout, sensitivity, color = 'darkorange')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "# Compute the AUC and store it in a variable\n",
    "auc = roc_auc_score(y_test, prob_default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model discrimination and impact\n",
    "\n",
    "Confusion Matrix\n",
    "\n",
    "\n",
    "| True Negatives (Predicted = 0, Actual = 0)| False Positives (Predicted = 1, Actual - 0)|\n",
    "| --- | --- |\n",
    "| False Negatives (Predicted = 0, Actual = 1)| True Positives (Predicted = 1, Actual = 1)|\n",
    "\n",
    "Precision_0 = TN / (TN + FN)\n",
    "\n",
    "Precision_1 = TP / (TP + FP)\n",
    "\n",
    "Recall_0 = TN / (TN + FP)\n",
    "\n",
    "Recall_1 = TP / (TP + FN) = Proportion of true defaults predicted = Sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholds and confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the threshold for defaults to 0.5\n",
    "preds_df['loan_status'] = preds_df['prob_default'].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(confusion_matrix(y_test,preds_df['loan_status']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How thresholds affect performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reassign the values of loan status based on the new threshold\n",
    "preds_df['loan_status'] = preds_df['prob_default'].apply(lambda x: 1 if x > 0.4 else 0)\n",
    "\n",
    "# Store the number of loan defaults from the prediction data\n",
    "num_defaults = preds_df['loan_status'].value_counts()[1]\n",
    "\n",
    "# Store the default recall from the classification report\n",
    "default_recall = precision_recall_fscore_support(y_test,preds_df['loan_status'])[1][1]\n",
    "\n",
    "# Calculate the estimated impact of the new default recall rate\n",
    "print(avg_loan_amnt * num_defaults * (1 - default_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(thresh,def_recalls)\n",
    "plt.plot(thresh,nondef_recalls)\n",
    "plt.plot(thresh,accs)\n",
    "plt.xlabel(\"Probability Threshold\")\n",
    "plt.xticks(ticks)\n",
    "plt.legend([\"Default Recall\",\"Non-default Recall\",\"Model Accuracy\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosted Trees Using XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation and Implementation"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
