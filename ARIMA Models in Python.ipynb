{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARMA Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to time series and stationarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Load in the time series\n",
    "candy = pd.read_csv('candy_production.csv', \n",
    "            index_col='date',\n",
    "            parse_dates=True)\n",
    "\n",
    "# Plot and show the time series on axis ax1\n",
    "fig, ax1 = plt.subplots()\n",
    "candy.plot(ax=ax1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a train and test set\n",
    "candy_train = candy.loc[:'2006']\n",
    "candy_test = candy.loc['2007':]\n",
    "\n",
    "# Create an axis\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the train and test sets on the axis ax\n",
    "candy_train.plot(ax=ax)\n",
    "candy_test.plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making time series stationary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing for stationarity wit Augmented Dicky-Fuller\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import augmented dicky-fuller test function\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Run test\n",
    "result = adfuller(earthquake['earthquakes_per_year'])\n",
    "\n",
    "# Print test statistic\n",
    "print(result[0])\n",
    "\n",
    "# Print p-value\n",
    "print(result[1])\n",
    "\n",
    "# Print critical values\n",
    "print(result[4]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taking the difference\n",
    "* .diff() applyed twice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other tranforms\n",
    "\n",
    "Differencing should be the first transform you try to make a time series stationary. But sometimes it isn't the best option.\n",
    "\n",
    "A classic way of transforming stock time series is the log-return of the series. This is calculated as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "log\\_return(y_t) = log\\frac{y_{t}}{y_{t-1}}\n",
    "\\end{equation}\n",
    "\n",
    "The Amazon stock time series has already been loaded for you as amazon. You can calculate the log-return of this DataFrame by substituting:\n",
    "\n",
    " * y_t -> amazon\n",
    " * y_(t-1) -> amazon.shift(1)\n",
    " * log -> np.log()\n",
    "\n",
    "In this exercise you will compare the log-return transform and the first order difference of the Amazon stock time series to find which is better for making the time series stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the first difference and drop the nans\n",
    "amazon_diff = amazon.diff()\n",
    "amazon_diff = amazon_diff.dropna()\n",
    "\n",
    "# Run test and print\n",
    "result_diff = adfuller(amazon_diff['close'])\n",
    "print(result_diff)\n",
    "\n",
    "# Calculate log-return and drop nans\n",
    "amazon_log = np.log(amazon.div(amazon.shift(1)))\n",
    "amazon_log = amazon_log.dropna()\n",
    "\n",
    "# Run test and print\n",
    "result_log = adfuller(amazon_log['close'])\n",
    "print(result_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure of ARIMA models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AR Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MA Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ARMA Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ARMAX Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* X - Exogenous variable\n",
    "* ARMAX = ARMA + linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating ARMA data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data generation function and set random seed\n",
    "from statsmodels.tsa.arima_process import arma_generate_sample\n",
    "np.random.seed(3)\n",
    "\n",
    "# Set coefficients\n",
    "ar_coefs = [1, 0.2] # Negative coeficients\n",
    "ma_coefs = [1, 0.3, 0.4]\n",
    "\n",
    "# Generate data\n",
    "y = arma_generate_sample(ar_coefs, ma_coefs, nsample=100, scale=0.5)\n",
    "\n",
    "plt.plot(y)\n",
    "plt.ylabel(r'$y_t$')\n",
    "plt.xlabel(r'$t$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting Prelude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the ARMA model\n",
    "from statsmodels.tsa.arima_model import ARMA\n",
    "\n",
    "# Instantiate the ARMA model \n",
    "model = ARMA(y, order=(1,1))\n",
    "\n",
    "# Instantiate the ARMAX model\n",
    "model = ARMA(S1, order = (2,1), exog = S2)\n",
    "\n",
    "# Fit the model\n",
    "results = model.fit()\n",
    "\n",
    "# Print summary\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the Future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating one-step-ahead predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "one_step_forecast = results.get_prediction(start=-30)\n",
    "\n",
    "# Extract prediction mean\n",
    "mean_forecast = one_step_forecast.predicted_mean\n",
    "\n",
    "# Get confidence intervals of predictions\n",
    "confidence_intervals = one_step_forecast.conf_int()\n",
    "\n",
    "# Select lower and upper confidence limits\n",
    "lower_limits = confidence_intervals.loc[:,'lower close']\n",
    "upper_limits = confidence_intervals.loc[:,'upper close']\n",
    "\n",
    "# Print best estimate predictions\n",
    "print(mean_forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting one-step-ahead predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the amazon data\n",
    "plt.plot(amazon.index, amazon, label='observed')\n",
    "\n",
    "# plot your mean predictions\n",
    "plt.plot(mean_forecast.index, mean_forecast, color='r', label='forecast')\n",
    "\n",
    "# shade the area between your confidence limits\n",
    "plt.fill_between(lower_limits.index, lower_limits, \n",
    "               upper_limits, color='pink')\n",
    "\n",
    "# set labels, legends and show plot\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Amazon Stock Price - Close USD')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating dynamic forecasts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "dynamic_forecast = results.get_prediction(start = -30, dynamic=True)\n",
    "\n",
    "# Extract prediction mean\n",
    "mean_forecast = dynamic_forecast.predicted_mean\n",
    "\n",
    "# Get confidence intervals of predictions\n",
    "confidence_intervals = dynamic_forecast.conf_int()\n",
    "\n",
    "# Select lower and upper confidence limits\n",
    "lower_limits = confidence_intervals.loc[:,'lower close']\n",
    "upper_limits = confidence_intervals.loc[:,'upper close']\n",
    "\n",
    "# Print best estimate predictions\n",
    "print(mean_forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Differencing and fitting ARMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the first difference of the data\n",
    "amazon_diff = amazon.diff().dropna()\n",
    "\n",
    "# Create ARMA(2,2) model\n",
    "arma = SARIMAX(amazon_diff, order = (2,0,2))\n",
    "\n",
    "# Fit model\n",
    "arma_results = arma.fit()\n",
    "\n",
    "# Print fit summary\n",
    "print(arma_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unrolling ARMA forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make arma forecast of next 10 differences\n",
    "arma_diff_forecast = arma_results.get_forecast(steps=10).predicted_mean\n",
    "\n",
    "# Integrate the difference forecast\n",
    "arma_int_forecast = np.cumsum(arma_diff_forecast)\n",
    "\n",
    "# Make absolute value forecast\n",
    "arma_value_forecast = arma_int_forecast + amazon.iloc[-1,0]\n",
    "\n",
    "# Print forecast\n",
    "print(arma_value_forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ARIMA(2,1,2) model\n",
    "arima = SARIMAX(amazon, order = (2,1,2))\n",
    "\n",
    "# Fit ARIMA model\n",
    "arima_results = arima.fit()\n",
    "\n",
    "# Make ARIMA forecast of next 10 values\n",
    "arima_value_forecast = arima_results.get_forecast(steps=10).predicted_mean\n",
    "\n",
    "# Print forecast\n",
    "print(arima_value_forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Best of the Best Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACF & PCF (auto correlation and parcial auto correlation)\n",
    "\n",
    "* IF (ACF tails off) and (PACF cuts off after lag p): AR(p)\n",
    "* IF (ACF cuts off after q) and (APCF tails off): MA(q)\n",
    "* IF both tail: ARMA\n",
    "* IF (ACF values are high) and (tail slowly): non stationary\n",
    "* IF (ACF lag-1 = too negative): you took the difference too many times\n",
    "\n",
    "## AIC & BIC\n",
    "\n",
    "* AIC: Akaike information criteria\n",
    "* BIC: Bayesian information criteria\n",
    "\n",
    "Lower AIC and BIC indicate better models. They penalize excess of parameters.\n",
    "\n",
    "BIC focusses more on restricting model size and is better for choosing a explanatory model.\n",
    "\n",
    "AIC is better at choosing predictive models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Searching over model order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty list to store search results\n",
    "order_aic_bic=[]\n",
    "\n",
    "# Loop over p values from 0-2\n",
    "for p in range(3):\n",
    "  # Loop over q values from 0-2\n",
    "    for q in range(3):\n",
    "      \t# create and fit ARMA(p,q) model\n",
    "        model = SARIMAX(df, order=(p,0,q))\n",
    "        results = model.fit()\n",
    "        \n",
    "        # Append order and results tuple\n",
    "        order_aic_bic.append((p,q,results.aic, results.bic)),\n",
    "        \n",
    "# Construct DataFrame from order_aic_bic\n",
    "order_df = pd.DataFrame(order_aic_bic, \n",
    "                        columns=['p', 'q', 'AIC', 'BIC'])\n",
    "\n",
    "# Print order_df in order of increasing AIC\n",
    "print(order_df.sort_values('AIC'))\n",
    "\n",
    "# Print order_df in order of increasing BIC\n",
    "print(order_df.sort_values('BIC'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean absolute error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "model = SARIMAX(earthquake, order=(1,0,1))\n",
    "results = model.fit()\n",
    "\n",
    "# Calculate the mean absolute error from residuals\n",
    "mae = np.mean(np.abs(results.resid))\n",
    "\n",
    "# Print mean absolute error\n",
    "print(mae)\n",
    "\n",
    "# Make plot of time series for comparison\n",
    "earthquake.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diagnostic summary statistics\n",
    "\n",
    "It is important to know when you need to go back to the drawing board in model design. In this exercise you will use the residual test statistics in the results summary to decide whether a model is a good fit to a time series.\n",
    "\n",
    "Here is a reminder of the tests in the model summary:\n",
    "\n",
    "| Test | Null hypothesis  | P-value name  | IF|\n",
    "|---|---|---|---|\n",
    "|  Ljung-Box |  There are no correlations in the residual |  Prob(Q) | p<0.05 : correlated|\n",
    "|  Jarque-Bera |  The residuals are normally distributed | Prob(JB)  | p<0.05 : non normal|\n",
    "\n",
    "We reject the null hypothesis if the p-value < 0.05.\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit model\n",
    "model1 = SARIMAX(df, order=(3,0,1))\n",
    "results1 = model1.fit()\n",
    "\n",
    "# Print summary\n",
    "print(results1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot diagnostics\n",
    "\n",
    "|Test\t| Good fit |\n",
    "|---|---|\n",
    "|Standardized residual |\tThere are no obvious patterns in the residuals|\n",
    "|Histogram plus kde estimate | The KDE curve should be very similar to the normal distribution|\n",
    "|Normal Q-Q\t | Most of the data points should lie on the straight line|\n",
    "|Correlogram\t| 95% of correlations for lag greater than zero should not be significant|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit model\n",
    "model = SARIMAX(df, order=(1,1,1))\n",
    "results = model.fit()\n",
    "\n",
    "# Create the 4 diagostics plots\n",
    "results.plot_diagnostics()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box-Jenkins method\n",
    "\n",
    "From Raw data -> production model\n",
    "\n",
    "* Identification\n",
    "* Estimation\n",
    "* Model siagnostics\n",
    "\n",
    "#### Identification\n",
    "\n",
    "* Is the time series stationary?\n",
    "* What differencing will make it stationary?\n",
    "* What transforms will make it stationary?\n",
    "* What values of P and q are most promissing?\n",
    "    * Plot the time series\n",
    "    * Use audmented Dicky-fuller test\n",
    "    * Use transforms .diff(), np.log(), np.sqrt()\n",
    "    * Plot ACF/PACF and pick a model order.\n",
    "\n",
    "#### Estimation\n",
    "\n",
    "* Use data to train model coefficients\n",
    "* Choose between models using AIC and BIC\n",
    "\n",
    "#### Model Diagnostics\n",
    "\n",
    "* Are residuals uncorrelated?\n",
    "* Are residuals normally distributed?\n",
    "    * results.plot_diagnostics()\n",
    "    * results.summary()\n",
    "\n",
    "#### Is model ok?\n",
    "* Back to identification\n",
    "* Send to production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time series\n",
    "savings.plot()\n",
    "plt.show()\n",
    "\n",
    "# Run Dicky-Fuller test\n",
    "result = adfuller(savings.savings)\n",
    "\n",
    "# Print test statistic\n",
    "print(result[0])\n",
    "\n",
    "# Print p-value\n",
    "print(result[1])\n",
    "\n",
    "# Create figure\n",
    "fig, (ax1, ax2) = plt.subplots(2,1, figsize=(12,8))\n",
    " \n",
    "# Plot the ACF of savings on ax1\n",
    "plot_acf(savings, lags = 10, zero = False, ax = ax1)\n",
    "\n",
    "# Plot the PACF of savings on ax2\n",
    "ax2 = plot_pacf(savings, lags = 10,  zero = False, ax = ax2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over p values from 0-3\n",
    "for p in range(4):\n",
    "  \n",
    "  # Loop over q values from 0-3\n",
    "    for q in range(4):\n",
    "      try:\n",
    "        # Create and fit ARMA(p,q) model\n",
    "        model = SARIMAX(savings, order=(p,0,q), trend='c')\n",
    "        results = model.fit()\n",
    "        \n",
    "        # Print p, q, AIC, BIC\n",
    "        print(p, q, results.aic, results.bic)\n",
    "        \n",
    "      except:\n",
    "        print(p, q, None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit model\n",
    "model = SARIMAX(savings, order = (1, 0, 2), trend = 'c')\n",
    "results = model.fit()\n",
    "\n",
    "# Create the 4 diagostics plots\n",
    "results.plot_diagnostics()\n",
    "plt.show()\n",
    "\n",
    "# Print summary\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seasonal ARIMA Models (SARIMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seasonal decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import seasonal decompose\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Perform additive decomposition\n",
    "decomp = seasonal_decompose(milk_production['pounds_per_cow'], \n",
    "                            period=12)\n",
    "\n",
    "# Plot decomposition\n",
    "decomp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seasonal ACF and PACF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure and subplot\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# Plot the ACF on ax1\n",
    "plot_acf(water['water_consumers'], lags = 25, zero=False,  ax=ax1)\n",
    "\n",
    "# Show figure\n",
    "plt.show()\n",
    "\n",
    "# Subtract the rolling mean\n",
    "water_2 = water - water.rolling(15).mean()\n",
    "\n",
    "# Drop the NaN values\n",
    "water_2 = water_2.dropna()\n",
    "\n",
    "# Create figure and subplots\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# Plot the ACF\n",
    "plot_acf(water_2['water_consumers'], lags=25, zero=False, ax=ax1)\n",
    "\n",
    "# Show figure\n",
    "plt.show()\n",
    "\n",
    "# Components higher than the confidence interval means seasonal components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SARIMA models\n",
    "\n",
    "To fit a seasonal ARIMA, we fit 2 models:\n",
    "* One for the seasonal part.\n",
    "* One for the non seasonal part.\n",
    "\n",
    "\\begin{equation}\n",
    "SARIMA(p,d,q)(P,D,Q)_{S}\n",
    "\\end{equation}\n",
    "S: number of time steps per cycle\n",
    "\n",
    "### Seasonal differencing\n",
    "To make a time searies stationary, subtract a value from a season ago from the time series.\n",
    "\n",
    "To find the seasonal order, plot the ACF and PACF of the differeced time series at multiple season steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting SARIMA models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SARIMAX model\n",
    "model = SARIMAX(df1, order=(1,0,0), seasonal_order=(1,1,0,7))\n",
    "\n",
    "# Fit the model\n",
    "results = model.fit()\n",
    "\n",
    "# Print the results summary\n",
    "print(results.summary())\n",
    "\n",
    "# Create a SARIMAX model\n",
    "model = SARIMAX(df2, order = (2,1,1), seasonal_order = (1,0,0,4))\n",
    "\n",
    "# Fit the model\n",
    "results = model.fit()\n",
    "\n",
    "# Print the results summary\n",
    "print(results.summary())\n",
    "\n",
    "# Create a SARIMAX model\n",
    "model = SARIMAX(df3,  order = (1,1,0), seasonal_order = (0,1,1,12))\n",
    "\n",
    "# Fit the model\n",
    "results = model.fit()\n",
    "\n",
    "# Print the results summary\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing SARIMA order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the first and seasonal differences and drop NaNs\n",
    "aus_employment_diff = aus_employment.diff(1).diff(12).dropna()\n",
    "\n",
    "# Create the figure \n",
    "fig, (ax1, ax2) = plt.subplots(2,1,figsize=(8,6))\n",
    "\n",
    "# Plot the ACF on ax1\n",
    "plot_acf(aus_employment_diff, lags = 11, zero = False, ax = ax1)\n",
    "\n",
    "# Plot the PACF on ax2\n",
    "plot_pacf(aus_employment_diff, lags = 11, zero = False, ax = ax2)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Make list of lags\n",
    "lags = [12, 24, 36, 48, 60]\n",
    "\n",
    "# Create the figure \n",
    "fig, (ax1, ax2) = plt.subplots(2,1,figsize=(8,6))\n",
    "\n",
    "# Plot the ACF on ax1\n",
    "plot_acf(aus_employment_diff, lags = lags, zero = False, ax = ax1)\n",
    "\n",
    "# Plot the PACF on ax2\n",
    "plot_pacf(aus_employment_diff, lags = lags, zero = False, ax = ax2)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SARIMA vs ARIMA forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create ARIMA mean forecast\n",
    "arima_pred = arima_results.get_prediction(start = -25)\n",
    "arima_mean = arima_pred.predicted_mean\n",
    "\n",
    "# Create SARIMA mean forecast\n",
    "sarima_pred = sarima_results.get_prediction(start = -25)\n",
    "sarima_mean = sarima_pred.predicted_mean\n",
    "\n",
    "# Plot mean ARIMA and SARIMA predictions and observed\n",
    "plt.plot(dates, sarima_mean, label='SARIMA')\n",
    "plt.plot(dates, arima_mean, label='ARIMA')\n",
    "plt.plot(wisconsin_test, label='observed')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automation and saving to production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automated model selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pmdarima as pm\n",
    "import pmdarima as pm\n",
    "\n",
    "# Create auto_arima model\n",
    "model1 = pm.auto_arima(df1,\n",
    "                      seasonal=True, m=7,\n",
    "                      d=0, D=1, \n",
    "                 \t  max_p=2, max_q=2,\n",
    "                      trace=True,\n",
    "                      error_action='ignore',\n",
    "                      suppress_warnings=True)\n",
    "                       \n",
    "# Print model summary\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model2 = pm.auto_arima(df2,\n",
    "                      seasonal=False, \n",
    "                      d=1, \n",
    "                      trend='c',\n",
    "                 \t  max_p=2, max_q=2,\n",
    "                      trace=True,\n",
    "                      error_action='ignore',\n",
    "                      suppress_warnings=True) \n",
    "\n",
    "# Print model summary\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model for SARIMAX(p,1,q)(P,1,Q)7\n",
    "model3 = pm.auto_arima(df3,\n",
    "                      seasonal=True, m=7,\n",
    "                      d=1, D=1, \n",
    "                      start_p=1, start_q=1,\n",
    "                      max_p=1, max_q=1,\n",
    "                      max_P=1, max_Q=1,\n",
    "                      trace=True,\n",
    "                      error_action='ignore',\n",
    "                      suppress_warnings=True) \n",
    "\n",
    "# Print model summary\n",
    "print(model3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving and updating models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import joblib\n",
    "import joblib\n",
    "\n",
    "# Set model name\n",
    "filename = \"candy_model.pkl\"\n",
    "\n",
    "# Pickle it\n",
    "joblib.dump(model,filename)\n",
    "\n",
    "# Load the model back in\n",
    "loaded_model = joblib.load(filename)\n",
    "\n",
    "# Update the model\n",
    "loaded_model.update(df_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Box-Jenkins with seasonal data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D should be 0 or 1\n",
    "\n",
    "d + D should be 0-2 \n",
    "\n",
    "Take the log of the data if the relations between seasonal and non seasonal componentes are multiplicative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sarima model diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model class\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# Create model object\n",
    "model = SARIMAX(co2, \n",
    "                order=(1,1,1), \n",
    "                seasonal_order=(0,1,1,12), \n",
    "                trend='c')\n",
    "# Fit model\n",
    "results = model.fit()\n",
    "\n",
    "# Plot common diagnostics\n",
    "results.plot_diagnostics()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create forecast object\n",
    "forecast_object = results.get_forecast(steps = 136)\n",
    "\n",
    "# Extract predicted mean attribute\n",
    "mean = forecast_object.predicted_mean\n",
    "\n",
    "# Calculate the confidence intervals\n",
    "conf_int = forecast_object.conf_int()\n",
    "\n",
    "# Extract the forecast dates\n",
    "dates = mean.index\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Plot past CO2 levels\n",
    "plt.plot(co2.index, co2, label='past')\n",
    "\n",
    "# Plot the prediction means as line\n",
    "plt.plot(dates, mean, label='predicted')\n",
    "\n",
    "# Shade between the confidence intervals\n",
    "plt.fill_between(dates, conf_int['lower CO2_ppm'], conf_int['upper CO2_ppm'], alpha=0.2)\n",
    "\n",
    "# Plot legend and show figure\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Print last predicted mean\n",
    "print(mean.iloc[-1])\n",
    "\n",
    "# Print last confidence interval\n",
    "print(conf_int.iloc[-1])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9de5594652ec9d8d2a7e3ffc93716e44f9fefa6fef95dd016388541308ca1759"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
